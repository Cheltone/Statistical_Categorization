---
title: "HW5_MeltonandBrink"
author: "Chad Melton"
date: "11/1/2020"
output: html_document
---

```{r}



library(MASS)
library(rpart)
library(epiR)
library(ggplot2)
library(vcdExtra)
library(vcd)
library(lmtest)
library(caret)
library(ROCR)
library(pROC)



crab = read.csv("C:\\Users\\chadm\\OneDrive\\Desktop\\Fall_2020\\STATS 578\\HW\\HW5\\crab.csv",header=TRUE)
```




## 5.10
For the horseshoe crab data, fit the logistic regression model with x = weight
as the sole predictor of the presence of satellites.'
```{r}

crab.model <- glm(y~weight, data=crab, family=binomial(link="logit"))
summary(crab.model)

```

y=-3.6947 +1.8151x
\
\

a. For a classification table using the sample proportion of 0.642 as the cutoff,
report the sensitivity and specificity. Interpret.'

```{r}
prob_pred = predict(crab.model, type = 'response')
y_thresh = ifelse(prob_pred > 0.642,1,0)
confusionMatrix(table(predict(crab.model, type="response") >= 0.642, crab$y == 1))
```

Here, the Sensitivity is 0.7258 and the Specificity is 0.6126. The sensitivy value suggests that ~72.58 percent would have attached crabs at the requested threshold.
The specificity value suggests that ~61.26 percent of unattached would be correctly identified by this model at the requested threshold.
\
\

b. Form a ROC curve, and report and interpret the area under it.

```{r}
crab.fit = predict(crab.model, type = "response")
pred.roc = prediction(crab.fit, crab$y)
perf.roc = performance(pred.roc,"tpr","fpr")
plot(perf.roc, main = "Weight Model Curve")


library(pROC)
rocCurve=roc(response = crab$y,predictor = crab.fit)
auc(rocCurve)  
plot(rocCurve,legacy.axes=TRUE)
ci(rocCurve)
```

\
\
c. Investigate the model goodness-of-fit using the Hosmer–Lemeshowstatistic
or some other model-checking approach. Interpret.

```{r}

library(ResourceSelection)
hos = hoslem.test(crab.model$y, fitted(crab.model), g = 10)
hos

```

Here, Hosmer and Lemeshow goodness of fit (GOF) test provides a p-value of 0.4499 which is substantially greater than 0.05.
Therefore, we will fail to reject the null hypothesis that the model is a bad fit.'
\
\

d. Inferentially compare the model to the model with x and x2 as predictors.
Interpret.'

```{r}

crab.model2 <- glm(y~weight+weight2, data=crab, family=binomial(link="logit"))
summary(crab.model2)
```


For the first crab model, the equation is y = -3.6947 + 1.8151x where the model with weight^2 is y = -1.8877+ 0.2182x + 0.3393x^2. The intercept and coefficients for
the first model are significant where as adding weight^2 drastically changes the significance.
weight        1.8151
\
\
e. Compare the models in (d) using the AIC. Interpret.'
AIC(crab.model)
AIC(crab.model2)
The AIC goodness of fit test suggests that crab.model is better fit than crab.model2 (199.7371<201.4605)'
\
\

##5.20

Refer to Table 2.7 on mother’s drinking and infant malformations.'

```{r}

birthdefects <- matrix(
  c(17066, 48, 0.0,14464,38,0.5, 788,5,1.5, 126,1,4.0, 37,1, 7.0), nrow=5, ncol=3, byrow=TRUE)
dimnames(birthdefects) <- list(alcohol=c("0","<1", "1-2", "3-5",">=6"),
                               defects=c( "No", "Yes", "Scores"))

as.data.frame(birthdefects)
birthdefects = as.data.frame(birthdefects)

bdfcts.model = glm(cbind(Yes, No)~Scores,data=birthdefects,family=binomial)
summary(bdfcts.model)

```

a. Fit the logistic regression model using scores {0, 0.5, 1.5, 4, 7} for alcohol
consumption. Check goodness of fit.'

```{r}


bdfcts.model = glm(cbind(Yes, No)~Scores,data=birthdefects,family=binomial)
summary(bdfcts.model)

pchisq(1.9487,3, lower.tail = FALSE)

```
The test provides a  p-value of 0.58 which suggests we fail to reject the null hypothesis that the model 
has a poor fit. This conclusion is supported by the ratio Residual Deviance to degrees of freedom ~2/3

\
\
b. Test independence using the likelihood-ratio test for the model in (a). (The
trend test of Section 2.5.1 is the score test for this model.)'


```{r}
lrtest (bdfcts.model)
```

'c. The sample proportion of malformations is much higher in the highest
alcohol category because, although it has only one malformation, its sample
size is only 38. Are the results sensitive to this single observation? Re-fit
the model without it, entering 0 malformations for 37 observations, and
compare the results of the likelihood-ratio test. (Because results are sensitive
to a single observation, it is hazardous to make conclusions, even though n
was extremely large.)'
```{r}

birthdefects2 <- matrix(
  c(17066, 48, 0.0,14464,38,0.5, 788,5,1.5, 126,1,4.0, 0,1, 7.0), nrow=5, ncol=3, byrow=TRUE)
dimnames(birthdefects2) <- list(alcohol=c("0","<1", "1-2", "3-5",">=6"),
                               defects=c( "No", "Yes", "Scores"))


birthdefects2 = as.data.frame(birthdefects2)

bdfcts2.model = glm(cbind(Yes, No)~Scores,data=birthdefects2,family=binomial)
summary(bdfcts2.model)

lrtest (bdfcts2.model)

```

The LRT of B provided a P-Value of 0.03917 while the result with the zeroed parameter was 0.0098, significantly
smaller. The substantial lessening in pvalues between both tests do suggest that the model is sensative to the single
observation.'
\
\
d. Fit the model and conduct the test of independence for all the data using
scores {1, 2, 3, 4, 5}. Compare the results with (b). (Results for highly
unbalanced data can be sensitive to the choice of scores.)'
```{r}

birthdefects3 <- matrix(
  c(17066, 48, 1,14464,38,2, 788,5,3, 126,1,4.0, 0,1, 5), nrow=5, ncol=3, byrow=TRUE)
dimnames(birthdefects3) <- list(alcohol=c("0","<1", "1-2", "3-5",">=6"),
                                defects=c( "No", "Yes", "Scores"))

birthdefects3 = as.data.frame(birthdefects3)

bdfcts3.model = glm(cbind(Yes, No)~Scores,data=birthdefects3,family=binomial)
summary(bdfcts2.model)
pchisq(8.4319,3,lower.tail = FALSE )

```
\
\
## 5.21


```{r}

birthdefects <- matrix(
  c(17066, 48, 14464,38,788,5,126,1,37,1), nrow=5, ncol=2, byrow=TRUE)
dimnames(birthdefects) <- list(alcohol=c("0","<1", "1-2", "3-5",">=6"),
                               defects=c("Yes", "No"))
fisher.test(birthdefects)
```


## Problem 5.23

### Part a

We start the problem by fitting the model to the data as requested. 

```{r}
library(survival)
library(MASS)
library(lmtest)
data23=read.csv(".\\Pr5.23.csv")
data23.fit=glm(cbind(response,count)~delay+pen1+pen2+pen3+pen4+pen5-1,data=data23,family=binomial(link="logit"))
summary(data23.fit)
```

We see that the last coefficient in the penicillan category has a very insignificant p-value. For the first value, the model gives us a significant coefficient that is within the realm of possibility. We can see from the data that these values should approach infinity and negative infinity respectively. However the answers reported make logical sense if we just look at the values. This indicates that the model does not perform as expected when zeros are present. It should also be noted that if this model is run with an intercept term, the last penicillan vlaue is null and the first has a much larger standard deviation.   

### Part b

Here we run the models for each of the likelihood ratios. 

```{r}

data23b=read.csv(".\\Pr5.23_b.csv")
data23b.fit1=glm(cbind(response,count)~delay+pen1-1,data=data23,family=binomial(link="logit"))
lrtest(data23b.fit1)
```

```{r}
data23b.fit2=glm(cbind(response,count)~delay+pen2-1,data=data23,family=binomial(link="logit"))
lrtest(data23b.fit2)
```


```{r}
data23b.fit3=glm(cbind(response,count)~delay+pen3-1,data=data23,family=binomial(link="logit"))
lrtest(data23b.fit3)
```

```{r}
data23b.fit4=glm(cbind(response,count)~delay+pen4-1,data=data23,family=binomial(link="logit"))
lrtest(data23b.fit4)
```

```{r}
data23b.fit5=glm(cbind(response,count)~delay+pen5-1,data=data23,family=binomial(link="logit"))
lrtest(data23b.fit5)
```

```{r}
data23b.fit=glm(cbind(response,count)~delay+pen1+pen2+pen3+pen4+pen5-1,data=data23,family=binomial(link="logit"))
lrtest(data23b.fit)
```

For the first two parameters the LR test produces very similar results to the null which indicates that there is some sort of independence. The other parmeters however do not produce results similar to the null which indicates some sort of dependence. The model with all parameters again produces a result that would indicate independence on x, however with a very insignificant p-value. 

### Part c

Here we compare the odds ratios for the models to calculate the conditional odds ratio.  This is the odds ratio of the model with all parameters over the model with the first parameter with the coefficient effect multiplied by five. If independent of x, this ratio should be equal to one. 

```{r}
a=sum(exp(coef(data23b.fit)))
b=exp(coef(data23b.fit1))
c=b[1]+b[2]*5
odds=a/c
odds
```

Here the odds ratio is slightly above one, but greatly enough that we assume there is some sort of dependence between x and y. 

## Problem 5.26
### Part a

We start this problem by loading the data and setting up a model for each feature. A brief discussion of each coefficient follows the model for that feature.

```{r}
tab15=read.csv(".\\Tab515.csv")
data.fitx1=glm(y~x1,data=tab15,family=binomial(link="logit"))
summary(data.fitx1)
```
For x1, we see that the model has a coefficient of -0.6383 and a standard deviation of 0.3808. Looking at the p-value, we see that this feature is not significant at a 95% confidence level. We now repeat the process for x2. 

```{r}
data.fitx2=glm(y~x2,data=tab15,family=binomial(link="logit"))
summary(data.fitx2)
```

In this model, we see that x2 has a coefficient of -0.3096 and a standard deviation of 0.1555. This feature is significant at a confidence level of 95%. We repeat yet again for x3.

```{r}
data.fitx3=glm(y~x3,data=tab15,family=binomial(link="logit"))
summary(data.fitx3)
```

In this final (for part a) model, we see that the feature x3 has a coefficient of 0.0117 and a standard deviation of 0.03224. The standard deviation is nearly three times the value of the coefficient so we are highly suspicious of the quality of this model. We can see that this feature is insginificant. 

### Part b

Now we look at a main features model containing a coefficient for each feature. We set up this model and run it below.

```{r}
data.fit=glm(y~x1+x2+x3,data=tab15,family=binomial(link="logit"))
summary(data.fit)
```

The first thing we note is that we get a convergence error when we run this model. Looking at the coefficeints for parameters with this error in mind we see that we get large coefficients. We get standard errors that are orders of magnitude greater than all the coefficents. All coefficients also have exactly the same p-value of 0.975. This shows that none of them are significant in this model. 

### Part c

We originally had this set up in R, however as the results did not make sense and Dr. Zaretzki said that this did not perform as desired we tried to set this up in SAS we ran out of time to produce this code and could not re-do the problem in SAS with our other responsibilites between class and the due date. Thank you for your understanding.  Below is the rcode used that did not make sense.

```{r}
data.conditional=clogit(y~x1+x2+x3,data=tab15,method="exact")
summary(data.conditional)
```

```{r}
data.conditional1=clogit(y~x1,data=tab15,method="exact")
summary(data.conditional1)
```

```{r}
data.conditional2=clogit(y~x2,data=tab15,method="exact")
summary(data.conditional2)
```

```{r}
data.conditional3=clogit(y~x3,data=tab15,method="exact")
summary(data.conditional3)
```
## Problem 5.28

### Part a
Here we use JMP to calculate the size of sample needed. The image of the program for this part is shown below. 
![Caption for the picture.](./HW5_5.28a.png)